{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Generate KdV Soliton Samples (RK4, RK3)\n\nGenerates one tidy DataFrame with soliton solutions using parallel computation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nfrom concurrent.futures import ProcessPoolExecutor, as_completed\n\nfrom spectral.tdp import KdVSolver, soliton, RK4, RK3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "DATA_DIR = Path(\"data/A2/ex_c\")\nDATA_DIR.mkdir(parents=True, exist_ok=True)\n\nL, x0, T = 30.0, 0.0, 20.0\nc_vals = [0.25, 0.5, 1.0]  # different wave speeds\nN_vals = [200]  # different spatial resolutions\n\ndt_scales = [0.4, 0.2]  # build dt ladder: dt = dt0 * scale\nsave_every_steps = 100\nmax_workers = os.cpu_count() or 4\n\nMETHODS = (\"RK4\", \"RK3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def estimate_stable_dt(N: int, method_name: str, c: float, fallback=1e-2) -> float:\n    \"\"\"Estimate dt0 per (N, method, c) from initial u_max.\"\"\"\n    s = KdVSolver(N, L)\n    u_max = float(np.max(np.abs(soliton(s.x, 0.0, c, x0))))\n    dt_est = KdVSolver.stable_dt(N, L, u_max, integrator_name=method_name.lower())\n    return float(dt_est) if np.isfinite(dt_est) else float(fallback)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def solve_single_case(method: str, N: int, dt: float, c: float):\n    \"\"\"Solve one (method, N, dt, c) case and return tidy DataFrame.\"\"\"\n    # Setup integrator\n    integrator_map = {\"RK4\": RK4, \"RK3\": RK3}\n    integ = integrator_map[method]()\n\n    # Setup solver\n    solver = KdVSolver(N, L)\n    x = solver.x\n    dx = solver.dx\n    u0 = soliton(x, 0.0, c, x0)\n\n    # Clear history for multi-step methods\n    if hasattr(integ, \"u_history\"):\n        integ.u_history, integ.f_history = [], []\n\n    # Solve\n    t_saved, u_hist = solver.solve(\n        u0.copy(), T, dt, integrator=integ, save_every=save_every_steps\n    )\n\n    # Build tidy DataFrame\n    dfs = []\n    for t, u in zip(t_saved, u_hist):\n        df_t = pd.DataFrame(\n            {\n                \"x\": x,\n                \"u\": u,\n                \"u_exact\": soliton(x, float(t), c, x0),\n                \"t\": t,\n            }\n        )\n        dfs.append(df_t)\n\n    df = pd.concat(dfs, ignore_index=True)\n\n    # Add metadata (pandas broadcasts scalars)\n    df[\"method\"] = method\n    df[\"N\"] = N\n    df[\"dx\"] = dx\n    df[\"dt\"] = dt\n    df[\"T\"] = T\n    df[\"c\"] = c\n    df[\"x0\"] = x0\n    df[\"L\"] = L\n\n    return df\n\n\nif __name__ == \"__main__\":\n    # %% Build task list\n    tasks = []\n    for method in METHODS:\n        for c in c_vals:\n            for N in N_vals:\n                dt0 = estimate_stable_dt(N, method, c, fallback=1e-2)\n                for scale in dt_scales:\n                    tasks.append((method, N, float(dt0 * scale), c))\n\n    # Deduplicate tasks just in case\n    # tasks = sorted(set(tasks))\n\n    print(f\"Generated {len(tasks)} tasks for parallel execution\")\n\n    # %% Run all cases in parallel\n    dfs = []\n    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n        futures = {\n            executor.submit(solve_single_case, m, N, dt, c): (m, N, dt, c)\n            for (m, N, dt, c) in tasks\n        }\n\n        for future in as_completed(futures):\n            m, N, dt, c = futures[future]\n            try:\n                dfs.append(future.result())\n            except Exception as e:\n                # On failure, record a placeholder row with NaNs\n                dfs.append(\n                    pd.DataFrame(\n                        [\n                            {\n                                \"method\": m,\n                                \"N\": np.int32(N),\n                                \"dx\": np.nan,\n                                \"dt\": np.float32(dt),\n                                \"T\": np.float32(T),\n                                \"t\": np.nan,\n                                \"x\": np.nan,\n                                \"u\": np.nan,\n                                \"u_exact\": np.nan,\n                                \"c\": np.float32(c),\n                                \"x0\": np.float32(x0),\n                                \"L\": np.float32(L),\n                            }\n                        ]\n                    )\n                )\n                print(\n                    f\"[warn] case failed: method={m}, N={N}, dt={dt:.3e}, c={c} -> {e}\"\n                )\n\n    # %% Concatenate and save\n    df = pd.concat(dfs, ignore_index=True)\n    df[\"method\"] = df[\"method\"].astype(\"category\")\n\n    out = DATA_DIR / \"kdv_solutions.parquet\"\n    df.to_parquet(out, index=False)\n\n    print(f\"Saved {len(df):,} rows \u2192 {out}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}