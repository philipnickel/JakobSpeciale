{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Scalability Analysis for KdV Solver\n\nMeasures sequential performance (computational complexity):\n\n- Wall time vs N for single cases\n- Compare all methods: RK4, RK3\n- Expected scaling: O(N log N) due to FFT operations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\nimport time\n\nimport numpy as np\nimport pandas as pd\n\nfrom spectral.tdp import KdVSolver, soliton, RK4, RK3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "DATA_DIR = Path(\"data/A2/ex_g\")\nDATA_DIR.mkdir(parents=True, exist_ok=True)\n\n# Timing parameters\nL = 30.0\nc = 0.5\nx0 = 0.0\nT_timing = 1.0  # Very short simulation for timing\nMETHODS = (\"RK4\", \"RK3\")\n\n# Sequential timing: vary N (extended range to see asymptotic behavior)\nN_values = [32, 64, 128, 256, 512]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def estimate_stable_dt(\n    N: int, L: float, method_name: str, c: float, safety_factor=0.1\n) -> float:\n    \"\"\"Estimate stable dt with safety factor.\"\"\"\n    s = KdVSolver(N, L)\n    u_max = float(np.max(np.abs(soliton(s.x, 0.0, c, x0))))\n    dt_est = KdVSolver.stable_dt(N, L, u_max, integrator_name=method_name.lower())\n    dt_safe = safety_factor * dt_est if np.isfinite(dt_est) else 1e-3\n    return float(dt_safe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def time_single_case(method: str, N: int, L: float, c: float, T: float):\n    \"\"\"Time a single case and return timing metrics.\"\"\"\n    # Setup integrator\n    integrator_map = {\"RK4\": RK4, \"RK3\": RK3}\n    integ = integrator_map[method]()\n\n    # Setup solver\n    solver = KdVSolver(N, L)\n    x = solver.x\n    u0 = soliton(x, 0.0, c, x0)\n\n    # Estimate stable dt\n    dt = estimate_stable_dt(N, L, method, c, safety_factor=0.1)\n\n    # Clear history for multi-step methods\n    if hasattr(integ, \"u_history\"):\n        integ.u_history, integ.f_history = [], []\n\n    # Time the solve (use performance measurement)\n    start_time = time.perf_counter()\n    t_saved, u_hist, perf_metrics = solver.solve(\n        u0.copy(),\n        T,\n        dt,\n        integrator=integ,\n        save_every=1000000,  # Don't save intermediate\n        measure_performance=True,\n    )\n    end_time = time.perf_counter()\n\n    wall_time = end_time - start_time\n    n_steps = perf_metrics[\"nsteps\"]\n    time_per_step = perf_metrics[\"mean_step_time_ms\"] / 1000.0  # Convert ms to s\n\n    return {\n        \"method\": method,\n        \"N\": N,\n        \"L\": L,\n        \"c\": c,\n        \"T\": T,\n        \"dt\": dt,\n        \"n_steps\": n_steps,\n        \"wall_time\": wall_time,\n        \"time_per_step\": time_per_step,\n    }\n\n\nif __name__ == \"__main__\":\n    # %% Sequential performance (wall time vs N)\n    print(\"=\" * 60)\n    print(\"Sequential Performance Analysis (Wall Time vs N)\")\n    print(\"=\" * 60)\n\n    timing_results = []\n\n    for method in METHODS:\n        print(f\"\\n{method}:\")\n        for N in N_values:\n            print(f\"  N={N:4d}...\", end=\" \", flush=True)\n            result = time_single_case(method, N, L, c, T_timing)\n            timing_results.append(result)\n            print(\n                f\"time/step = {result['time_per_step']:.6f}s, total = {result['wall_time']:.3f}s\"\n            )\n\n    # Save sequential timing results\n    df_timing = pd.DataFrame(timing_results)\n    df_timing[\"method\"] = df_timing[\"method\"].astype(\"category\")\n    out_timing = DATA_DIR / \"scalability_timing.parquet\"\n    df_timing.to_parquet(out_timing, index=False)\n    print(f\"\\nSaved timing data to {out_timing}\")\n    print(f\"  Shape: {df_timing.shape}\")\n\n    print(\"\\n\" + \"=\" * 60)\n    print(\"Scalability analysis complete!\")\n    print(\"=\" * 60)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}