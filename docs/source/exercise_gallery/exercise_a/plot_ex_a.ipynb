{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Legendre Tau vs Collocation - Plotting\n\nVisualizes solution comparisons and coefficient decay for Legendre Tau and\nCollocation methods across different boundary layer widths.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and prepare data\nLoad the precomputed solutions and coefficient data from both methods.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nfrom spectral.utils.plotting import add_parameter_footer, get_repo_root\n\nrepo_root = get_repo_root()\ndata_dir = repo_root / \"data/A2/ex_a\"\nsave_dir = repo_root / \"figures/A2/ex_a\"\nsave_dir.mkdir(parents=True, exist_ok=True)\n\ndf = pd.read_parquet(data_dir / \"data.parquet\")\nprint(f\"Loaded unified data: {df.shape}\")\n\ndf_sol = df[df[\"data_type\"] == \"solution\"].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Solution comparison\nCompare Tau and Collocation solutions across different boundary layer widths.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "N = df_sol[\"N\"].iloc[0]\nn_eval_points = df_sol[\"x\"].nunique()\n\ng = sns.relplot(\n    data=df_sol,\n    x=\"x\",\n    y=\"u\",\n    hue=\"method\",\n    style=\"method\",\n    kind=\"line\",\n    col=\"eps\",\n    col_wrap=3,\n    facet_kws=dict(sharey=False, sharex=True),\n    height=4,\n    aspect=1.2,\n)\ng.set_titles(r\"$\\varepsilon={col_name:g}$\")\ng.set_axis_labels(r\"$x$\", r\"$u(x)$\")\ng.figure.suptitle(r\"Tau vs Collocation for different $\\varepsilon$\", y=1.02)\n\n# Add parameter footer\nadd_parameter_footer(g.figure, rf\"$N = {N}$ ({n_eval_points} Evaluation points)\")\n\noutput = save_dir / \"solutions_facet.pdf\"\ng.figure.savefig(output, bbox_inches=\"tight\")\nprint(f\"  Saved: {output}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Coefficient decay\nVisualize how Legendre coefficients decay for both methods.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df_coef = df[df[\"data_type\"] == \"coefficient\"]\ndf_coef2 = df_coef[df_coef[\"method\"] != \"Exact\"]\n\n# Filter out mode 0 for log scale\ndf_coef_plot = df_coef2[df_coef2[\"mode\"] > 0].copy()\ndf_coef_plot[\"method\"] = df_coef_plot[\"method\"].cat.remove_unused_categories()\n\n\ng2 = sns.relplot(\n    data=df_coef_plot,\n    x=\"mode\",\n    y=\"abs_coeff\",\n    hue=\"method\",\n    style=\"method\",\n    kind=\"line\",\n    col=\"eps\",\n    col_wrap=3,\n    marker=\"o\",\n    dashes=False,\n    height=4,\n    aspect=1.2,\n)\ng2.set(xscale=\"log\", yscale=\"log\", xlabel=r\"Legendre mode $n$\", ylabel=r\"$|c_n|$\")\ng2.set_titles(r\"$\\varepsilon={col_name:g}$\")\ng2.figure.suptitle(\"Coefficient Decay: Tau vs Collocation\", y=1.02)\n\n# Add parameter footer\nadd_parameter_footer(g2.figure, rf\"$N = {N}$ ({n_eval_points} Evaluation points)\")\n\noutput = save_dir / \"coefficients_facet.pdf\"\ng2.figure.savefig(output, bbox_inches=\"tight\")\nprint(f\"  Saved: {output}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Error profiles\nShow pointwise error distributions for both methods.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\nCreating error profiles...\")\ndf_sol = df_sol[df_sol[\"method\"] != \"Exact\"]\ndf_sol[\"method\"] = df_sol[\"method\"].cat.remove_unused_categories()\n\ng3 = sns.relplot(\n    data=df_sol,\n    x=\"x\",\n    y=\"pointwise_err\",\n    hue=\"method\",\n    style=\"method\",\n    kind=\"line\",\n    col=\"eps\",\n    col_wrap=3,\n    facet_kws=dict(sharey=False),\n    height=4,\n    aspect=1.2,\n)\ng3.set(yscale=\"log\", xlabel=r\"$x$\", ylabel=r\"$|u_{\\rm num}-u_{\\rm exact}|$\")\ng3.set_titles(r\"$\\varepsilon={col_name:g}$\")\ng3.figure.suptitle(\"Error Profiles: Tau vs Collocation\", y=1.02)\n\n# Add parameter footer\nadd_parameter_footer(g3.figure, rf\"$N = {N}$ ({n_eval_points} Evaluation points)\")\n\noutput = save_dir / \"errors_facet.pdf\"\ng3.figure.savefig(output, bbox_inches=\"tight\")\nprint(f\"  Saved: {output}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Convergence study\nAnalyze how error decreases with increasing number of modes.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\nCreating convergence plots...\")\nconvergence_df = pd.read_parquet(data_dir / \"convergence.parquet\")\n\n# Create faceted convergence plot\ng4 = sns.relplot(\n    data=convergence_df,\n    x=\"N\",\n    y=\"Linf_err\",\n    hue=\"method\",\n    style=\"method\",\n    kind=\"line\",\n    col=\"eps\",\n    col_wrap=3,\n    marker=\"o\",\n    facet_kws=dict(sharey=False),\n    height=4,\n    aspect=1.2,\n)\ng4.set(\n    xscale=\"log\",\n    yscale=\"log\",\n    xlabel=r\"Number of modes $N$\",\n    ylabel=r\"$L^\\infty$ Error\",\n)\ng4.set_titles(r\"$\\varepsilon={col_name:g}$\")\ng4.figure.suptitle(\"Convergence Study: Tau vs Collocation\", y=1.02)\n\n# Add reference lines to each subplot\nfor ax, (eps_val, group) in zip(\n    g4.axes.flat, convergence_df.groupby(\"eps\", observed=True)\n):\n    N_vals = group[\"N\"].unique()\n    N_ref = np.array([N_vals.min(), N_vals.max()])\n\n    # O(N^-2) reference line\n    slope = -2\n    err_ref_start = group[group[\"N\"] == N_vals.min()][\"Linf_err\"].max()\n    err_ref = err_ref_start * (N_ref / N_vals.min()) ** slope\n\n    ax.plot(\n        N_ref, err_ref, \"k--\", alpha=0.5, linewidth=1.5, label=r\"$\\mathcal{O}(N^{-2})$\"\n    )\n    ax.legend()\n\n# Add parameter footer (N range varies for convergence study)\nN_min = convergence_df[\"N\"].min()\nN_max = convergence_df[\"N\"].max()\n# Note: convergence data doesn't have x values, use main data for eval points\nadd_parameter_footer(\n    g4.figure, rf\"$N \\in [{N_min}, {N_max}]$ ({n_eval_points} Evaluation points)\"\n)\n\noutput = save_dir / \"convergence_facet.pdf\"\ng4.figure.savefig(output, bbox_inches=\"tight\")\nprint(f\"  Saved: {output}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}