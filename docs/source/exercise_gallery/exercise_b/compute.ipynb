{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Polar BVP - Data Generation\n\nData stored in tidy dataframes:\n\n1. convergence.parquet: Nr, Linf_err\n2. solution.parquet: r, phi, u, u_exact, pointwise_err, Nr, r1, r2, L2_err, Linf_err\n\nEach row in ex_b_solution.parquet represents one grid point (r, phi).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n\nimport numpy as np\nimport pandas as pd\n\nfrom spectral.bvp import solve_polar_bvp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_dir = Path(\"data/A2/ex_b\")\ndata_dir.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Running convergence study...\")\nNrs = np.arange(10, 50, step=2)\nerrors = np.zeros(Nrs.shape[0])\n\nr1 = 1\nr2 = 10\n\nfor i, Nr in enumerate(Nrs):\n    Phi, Phi_hat, Rs, Theta = solve_polar_bvp(r1, r2, Nr)\n    errors[i] = np.max(np.abs(Phi - Phi_hat))\n    print(f\"  Nr={Nr}: max error = {errors[i]:.6e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "convergence_df = pd.DataFrame({\"Nr\": Nrs, \"Linf_err\": errors})\nconvergence_df.to_parquet(data_dir / \"convergence.parquet\", index=False)\nprint(f\"Saved convergence data: {data_dir}/convergence.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\nSolving BVP for visualization...\")\nr1 = 1\nr2 = 3\nNr = 20\nPhi, Phi_hat, Rs, Theta = solve_polar_bvp(r1, r2, Nr)\n\nprint(f\"  Solution shape: {Phi.shape}\")\nprint(f\"  Max error: {np.max(np.abs(Phi - Phi_hat)):.6e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Flatten 2D grids into long-form data (one row per grid point)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pointwise_err = np.abs(Phi_hat - Phi)\ndx = np.diff(Rs[0, :])\ndx = np.append(dx, dx[-1])\ndy = np.diff(Theta[:, 0])\ndy = np.append(dy, dy[-1])\n\n# Compute global errors (approximate L2 using grid integration)\ndA = np.outer(dy, dx * Rs[0, :])  # Area element in polar coords: r*dr*d\u03b8\nL2_err = np.sqrt(np.sum(pointwise_err**2 * dA))\nLinf_err = np.max(pointwise_err)\n\nsolution_df = pd.DataFrame(\n    {\n        \"r\": Rs.flatten(),\n        \"phi\": Theta.flatten(),\n        \"u\": Phi_hat.flatten(),\n        \"u_exact\": Phi.flatten(),\n        \"pointwise_err\": pointwise_err.flatten(),\n        \"Nr\": Nr,\n        \"r1\": r1,\n        \"r2\": r2,\n        \"L2_err\": L2_err,\n        \"Linf_err\": Linf_err,\n    }\n)\n\nsolution_df.to_parquet(data_dir / \"solution.parquet\", index=False)\nprint(f\"Saved solution data: {data_dir}/solution.parquet\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}